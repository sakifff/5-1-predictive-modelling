{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Face Recognition, but not evil this time\n",
    "\n",
    "Using the faces dataset in:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "```\n",
    "\n",
    "If you use the `faces.target` and `faces.target_names` attributes, you can build a facial recognition algorithm.\n",
    "\n",
    "Use sklearn **gridsearch** (or an equivalent, like random search) to optimize the model for accuracy. Try both a SVM-based classifier and a logistic regression based classifier (with a feature pipeline of your choice) to get the best model. You should have at least 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.manifold import Isomap\n",
    "from matplotlib import offsetbox\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faces.data\n",
    "y = faces.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 2914)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM based classifier\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA(n_components = 150, svd_solver ='randomized',\n",
    "            whiten = True)),\n",
    "    ('std', StandardScaler()),\n",
    "    ('clf', GridSearchCV(SVC(kernel ='rbf', class_weight ='balanced'), param_grid))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555555555555555"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  1  0  3  0  0  0  0]\n",
      " [ 1 44  1  4  0  0  0  1]\n",
      " [ 0  1 20  4  0  0  0  0]\n",
      " [ 0  3  1 94  0  0  0  0]\n",
      " [ 0  0  0  4 15  0  0  2]\n",
      " [ 0  1  0  4  0  9  0  1]\n",
      " [ 0  1  0  1  0  0  8  0]\n",
      " [ 0  0  0  5  0  0  0 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.86      0.86      0.86        51\n",
      "           2       0.91      0.80      0.85        25\n",
      "           3       0.79      0.96      0.87        98\n",
      "           4       1.00      0.71      0.83        21\n",
      "           5       1.00      0.60      0.75        15\n",
      "           6       1.00      0.80      0.89        10\n",
      "           7       0.89      0.87      0.88        38\n",
      "\n",
      "    accuracy                           0.86       270\n",
      "   macro avg       0.92      0.78      0.84       270\n",
      "weighted avg       0.87      0.86      0.85       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression classifier\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8185185185185185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8518518518518519"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('reg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  2  1  1  0  0  0]\n",
      " [ 2 42  2  3  0  0  0  2]\n",
      " [ 0  2 18  4  0  0  0  1]\n",
      " [ 1  4  3 84  2  2  0  2]\n",
      " [ 1  0  0  1 17  0  1  1]\n",
      " [ 0  1  0  1  3 10  0  0]\n",
      " [ 0  0  0  0  0  0 10  0]\n",
      " [ 1  0  0  4  1  0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64        12\n",
      "           1       0.86      0.82      0.84        51\n",
      "           2       0.72      0.72      0.72        25\n",
      "           3       0.86      0.86      0.86        98\n",
      "           4       0.71      0.81      0.76        21\n",
      "           5       0.83      0.67      0.74        15\n",
      "           6       0.91      1.00      0.95        10\n",
      "           7       0.84      0.84      0.84        38\n",
      "\n",
      "    accuracy                           0.82       270\n",
      "   macro avg       0.79      0.80      0.79       270\n",
      "weighted avg       0.82      0.82      0.82       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Judging by the results, it seems like both classifiers give similar results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Bag of Words, Bag of Popcorn\n",
    "\n",
    "By this point, you are ready for the [Bag of Words, Bag of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. \n",
    "\n",
    "Use NLP feature pre-processing (using, SKLearn, Gensim, Spacy or Hugginface) to build the best classifier you can. Use a  feature pipeline, and gridsearch for your final model.\n",
    "\n",
    "A succesful project should get 90% or more on a **holdout** dataset you kept for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/labeledTrainData.tsv', sep='\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2509</th>\n",
       "      <th>2510</th>\n",
       "      <th>2511</th>\n",
       "      <th>2512</th>\n",
       "      <th>2513</th>\n",
       "      <th>2514</th>\n",
       "      <th>2515</th>\n",
       "      <th>2516</th>\n",
       "      <th>2517</th>\n",
       "      <th>2518</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>all</td>\n",
       "      <td>this</td>\n",
       "      <td>stuff</td>\n",
       "      <td>going</td>\n",
       "      <td>down</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>moment</td>\n",
       "      <td>with</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>classic</td>\n",
       "      <td>war</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>worlds</td>\n",
       "      <td>by</td>\n",
       "      <td>timothy</td>\n",
       "      <td>hines</td>\n",
       "      <td>is</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>starts</td>\n",
       "      <td>with</td>\n",
       "      <td>a</td>\n",
       "      <td>manager</td>\n",
       "      <td>nicholas</td>\n",
       "      <td>bell</td>\n",
       "      <td>giving</td>\n",
       "      <td>welcome</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>must</td>\n",
       "      <td>be</td>\n",
       "      <td>assumed</td>\n",
       "      <td>that</td>\n",
       "      <td>those</td>\n",
       "      <td>who</td>\n",
       "      <td>praised</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly</td>\n",
       "      <td>trashy</td>\n",
       "      <td>and</td>\n",
       "      <td>wondrously</td>\n",
       "      <td>unpretentious</td>\n",
       "      <td>80</td>\n",
       "      <td>s</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>hooray</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>it</td>\n",
       "      <td>seems</td>\n",
       "      <td>like</td>\n",
       "      <td>more</td>\n",
       "      <td>consideration</td>\n",
       "      <td>has</td>\n",
       "      <td>gone</td>\n",
       "      <td>into</td>\n",
       "      <td>the</td>\n",
       "      <td>imdb</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>i</td>\n",
       "      <td>don</td>\n",
       "      <td>t</td>\n",
       "      <td>believe</td>\n",
       "      <td>they</td>\n",
       "      <td>made</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>completely</td>\n",
       "      <td>unnecessary</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy</td>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>loser</td>\n",
       "      <td>can</td>\n",
       "      <td>t</td>\n",
       "      <td>get</td>\n",
       "      <td>girls</td>\n",
       "      <td>needs</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>this</td>\n",
       "      <td>30</td>\n",
       "      <td>minute</td>\n",
       "      <td>documentary</td>\n",
       "      <td>buñuel</td>\n",
       "      <td>made</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>early</td>\n",
       "      <td>1930</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>i</td>\n",
       "      <td>saw</td>\n",
       "      <td>this</td>\n",
       "      <td>movie</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>child</td>\n",
       "      <td>and</td>\n",
       "      <td>it</td>\n",
       "      <td>broke</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1       2            3              4        5     \\\n",
       "0          with      all    this        stuff          going     down   \n",
       "1           the  classic     war           of            the   worlds   \n",
       "2           the     film  starts         with              a  manager   \n",
       "3            it     must      be      assumed           that    those   \n",
       "4      superbly   trashy     and   wondrously  unpretentious       80   \n",
       "...         ...      ...     ...          ...            ...      ...   \n",
       "24995        it    seems    like         more  consideration      has   \n",
       "24996         i      don       t      believe           they     made   \n",
       "24997       guy       is       a        loser            can        t   \n",
       "24998      this       30  minute  documentary         buñuel     made   \n",
       "24999         i      saw    this        movie             as        a   \n",
       "\n",
       "           6             7           8            9     ...  2509  2510  2511  \\\n",
       "0            at           the      moment         with  ...  None  None  None   \n",
       "1            by       timothy       hines           is  ...  None  None  None   \n",
       "2      nicholas          bell      giving      welcome  ...  None  None  None   \n",
       "3           who       praised        this         film  ...  None  None  None   \n",
       "4             s  exploitation      hooray          the  ...  None  None  None   \n",
       "...         ...           ...         ...          ...  ...   ...   ...   ...   \n",
       "24995      gone          into         the         imdb  ...  None  None  None   \n",
       "24996      this          film  completely  unnecessary  ...  None  None  None   \n",
       "24997       get         girls       needs           to  ...  None  None  None   \n",
       "24998        in           the       early         1930  ...  None  None  None   \n",
       "24999     child           and          it        broke  ...  None  None  None   \n",
       "\n",
       "       2512  2513  2514  2515  2516  2517  2518  \n",
       "0      None  None  None  None  None  None  None  \n",
       "1      None  None  None  None  None  None  None  \n",
       "2      None  None  None  None  None  None  None  \n",
       "3      None  None  None  None  None  None  None  \n",
       "4      None  None  None  None  None  None  None  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  \n",
       "24995  None  None  None  None  None  None  None  \n",
       "24996  None  None  None  None  None  None  None  \n",
       "24997  None  None  None  None  None  None  None  \n",
       "24998  None  None  None  None  None  None  None  \n",
       "24999  None  None  None  None  None  None  None  \n",
       "\n",
       "[25000 rows x 2519 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recycling the same gensim method from 4.7\n",
    "\n",
    "import re\n",
    "\n",
    "replaceDict = dict({\n",
    "'{':\" \", '}':\" \", ',':\"\", '.':\" \", '!':\" \", '\\\\':\" \", '/':\" \", '$':\" \", '%':\" \",\n",
    "'^':\" \", '?':\" \", '\\'':\" \", '\"':\" \", '(':\" \", ')':\" \", '*':\" \", '+':\" \", '-':\" \",\n",
    "'=':\" \", ':':\" \", ';':\" \", ']':\" \", '[':\" \", '`':\" \", '~':\" \",\n",
    "})\n",
    "\n",
    "rep = dict((re.escape(k), v) for k, v in replaceDict.items())\n",
    "\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "def replacer(text):\n",
    "    return rep[re.escape(text.group(0))]\n",
    "\n",
    "words = train.review.str.replace(pattern, replacer).str.lower().str.split()\n",
    "words = pd.DataFrame(words.tolist())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.283424</td>\n",
       "      <td>11.937847</td>\n",
       "      <td>18.506580</td>\n",
       "      <td>45.120676</td>\n",
       "      <td>-24.435819</td>\n",
       "      <td>3.551744</td>\n",
       "      <td>12.055645</td>\n",
       "      <td>-27.254570</td>\n",
       "      <td>30.983692</td>\n",
       "      <td>19.554092</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.531746</td>\n",
       "      <td>23.092484</td>\n",
       "      <td>-33.328987</td>\n",
       "      <td>9.722412</td>\n",
       "      <td>-26.716827</td>\n",
       "      <td>-10.303997</td>\n",
       "      <td>2.579872</td>\n",
       "      <td>-19.129990</td>\n",
       "      <td>11.317310</td>\n",
       "      <td>-4.080734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.778992</td>\n",
       "      <td>6.744947</td>\n",
       "      <td>3.544289</td>\n",
       "      <td>15.174940</td>\n",
       "      <td>-8.201431</td>\n",
       "      <td>0.314445</td>\n",
       "      <td>4.249725</td>\n",
       "      <td>-9.231554</td>\n",
       "      <td>7.977154</td>\n",
       "      <td>8.119308</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.727188</td>\n",
       "      <td>3.146690</td>\n",
       "      <td>-12.804749</td>\n",
       "      <td>3.808205</td>\n",
       "      <td>-6.146217</td>\n",
       "      <td>-2.835491</td>\n",
       "      <td>-0.495293</td>\n",
       "      <td>-4.693481</td>\n",
       "      <td>4.241936</td>\n",
       "      <td>-0.824364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.668854</td>\n",
       "      <td>18.400442</td>\n",
       "      <td>2.117029</td>\n",
       "      <td>24.500671</td>\n",
       "      <td>-17.646823</td>\n",
       "      <td>-1.491764</td>\n",
       "      <td>3.763025</td>\n",
       "      <td>-24.287819</td>\n",
       "      <td>18.558378</td>\n",
       "      <td>24.320732</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.039650</td>\n",
       "      <td>6.284547</td>\n",
       "      <td>-23.298676</td>\n",
       "      <td>15.287937</td>\n",
       "      <td>-12.791531</td>\n",
       "      <td>-5.257778</td>\n",
       "      <td>2.578659</td>\n",
       "      <td>-12.364639</td>\n",
       "      <td>8.910461</td>\n",
       "      <td>4.143981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.438416</td>\n",
       "      <td>9.676690</td>\n",
       "      <td>3.184448</td>\n",
       "      <td>28.120438</td>\n",
       "      <td>-22.092400</td>\n",
       "      <td>3.097771</td>\n",
       "      <td>14.640491</td>\n",
       "      <td>-28.468567</td>\n",
       "      <td>23.722717</td>\n",
       "      <td>22.710403</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.556366</td>\n",
       "      <td>4.002686</td>\n",
       "      <td>-23.584404</td>\n",
       "      <td>9.610126</td>\n",
       "      <td>-10.111442</td>\n",
       "      <td>-2.726578</td>\n",
       "      <td>3.336586</td>\n",
       "      <td>-10.713562</td>\n",
       "      <td>16.601911</td>\n",
       "      <td>3.251701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.447418</td>\n",
       "      <td>9.209012</td>\n",
       "      <td>8.393372</td>\n",
       "      <td>27.671641</td>\n",
       "      <td>-22.164581</td>\n",
       "      <td>1.606564</td>\n",
       "      <td>11.384158</td>\n",
       "      <td>-23.531187</td>\n",
       "      <td>22.702066</td>\n",
       "      <td>23.904671</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.457840</td>\n",
       "      <td>10.056759</td>\n",
       "      <td>-29.204399</td>\n",
       "      <td>6.255138</td>\n",
       "      <td>-14.498840</td>\n",
       "      <td>-0.895094</td>\n",
       "      <td>6.454372</td>\n",
       "      <td>-19.625992</td>\n",
       "      <td>0.599186</td>\n",
       "      <td>1.965607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>4.843140</td>\n",
       "      <td>3.083902</td>\n",
       "      <td>0.044777</td>\n",
       "      <td>8.552612</td>\n",
       "      <td>-7.245542</td>\n",
       "      <td>1.479004</td>\n",
       "      <td>4.257339</td>\n",
       "      <td>-4.647678</td>\n",
       "      <td>4.680054</td>\n",
       "      <td>2.775642</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.378468</td>\n",
       "      <td>6.225250</td>\n",
       "      <td>-7.275024</td>\n",
       "      <td>3.712402</td>\n",
       "      <td>-4.262329</td>\n",
       "      <td>-1.908768</td>\n",
       "      <td>4.530167</td>\n",
       "      <td>-3.873884</td>\n",
       "      <td>-0.512589</td>\n",
       "      <td>0.154842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>5.863220</td>\n",
       "      <td>2.340229</td>\n",
       "      <td>2.210129</td>\n",
       "      <td>12.314983</td>\n",
       "      <td>-7.772020</td>\n",
       "      <td>1.114616</td>\n",
       "      <td>10.503281</td>\n",
       "      <td>-13.057060</td>\n",
       "      <td>13.101852</td>\n",
       "      <td>12.770050</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.988598</td>\n",
       "      <td>6.903183</td>\n",
       "      <td>-15.212250</td>\n",
       "      <td>2.484120</td>\n",
       "      <td>-5.440849</td>\n",
       "      <td>-1.743176</td>\n",
       "      <td>2.057991</td>\n",
       "      <td>-6.311344</td>\n",
       "      <td>6.623047</td>\n",
       "      <td>-2.365334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2.160698</td>\n",
       "      <td>3.789089</td>\n",
       "      <td>-0.081245</td>\n",
       "      <td>13.001617</td>\n",
       "      <td>-8.620522</td>\n",
       "      <td>-1.689472</td>\n",
       "      <td>2.976837</td>\n",
       "      <td>-6.946411</td>\n",
       "      <td>7.065413</td>\n",
       "      <td>7.312721</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.426193</td>\n",
       "      <td>9.140686</td>\n",
       "      <td>-10.666756</td>\n",
       "      <td>4.078735</td>\n",
       "      <td>-6.753197</td>\n",
       "      <td>0.665543</td>\n",
       "      <td>-0.919044</td>\n",
       "      <td>-7.831268</td>\n",
       "      <td>3.209351</td>\n",
       "      <td>-2.725433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>9.051056</td>\n",
       "      <td>3.218176</td>\n",
       "      <td>9.683090</td>\n",
       "      <td>16.531189</td>\n",
       "      <td>-7.922881</td>\n",
       "      <td>3.315762</td>\n",
       "      <td>9.002274</td>\n",
       "      <td>-17.094444</td>\n",
       "      <td>12.638168</td>\n",
       "      <td>7.161171</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.743801</td>\n",
       "      <td>0.952118</td>\n",
       "      <td>-15.382585</td>\n",
       "      <td>2.369106</td>\n",
       "      <td>-11.096809</td>\n",
       "      <td>-1.904205</td>\n",
       "      <td>-0.214203</td>\n",
       "      <td>-5.103699</td>\n",
       "      <td>12.709579</td>\n",
       "      <td>-2.317215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>5.100037</td>\n",
       "      <td>7.309171</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>17.608094</td>\n",
       "      <td>-8.114711</td>\n",
       "      <td>2.118683</td>\n",
       "      <td>9.659119</td>\n",
       "      <td>-9.665316</td>\n",
       "      <td>13.272865</td>\n",
       "      <td>13.193047</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.379272</td>\n",
       "      <td>6.038727</td>\n",
       "      <td>-16.316090</td>\n",
       "      <td>5.599518</td>\n",
       "      <td>-8.328697</td>\n",
       "      <td>-1.204252</td>\n",
       "      <td>-1.484009</td>\n",
       "      <td>-5.121796</td>\n",
       "      <td>6.469944</td>\n",
       "      <td>-3.725159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4         5    \\\n",
       "0      17.283424  11.937847  18.506580  45.120676 -24.435819  3.551744   \n",
       "1       4.778992   6.744947   3.544289  15.174940  -8.201431  0.314445   \n",
       "2       7.668854  18.400442   2.117029  24.500671 -17.646823 -1.491764   \n",
       "3      13.438416   9.676690   3.184448  28.120438 -22.092400  3.097771   \n",
       "4      17.447418   9.209012   8.393372  27.671641 -22.164581  1.606564   \n",
       "...          ...        ...        ...        ...        ...       ...   \n",
       "24995   4.843140   3.083902   0.044777   8.552612  -7.245542  1.479004   \n",
       "24996   5.863220   2.340229   2.210129  12.314983  -7.772020  1.114616   \n",
       "24997   2.160698   3.789089  -0.081245  13.001617  -8.620522 -1.689472   \n",
       "24998   9.051056   3.218176   9.683090  16.531189  -7.922881  3.315762   \n",
       "24999   5.100037   7.309171  -0.032715  17.608094  -8.114711  2.118683   \n",
       "\n",
       "             6          7          8          9    ...        290        291  \\\n",
       "0      12.055645 -27.254570  30.983692  19.554092  ... -24.531746  23.092484   \n",
       "1       4.249725  -9.231554   7.977154   8.119308  ... -12.727188   3.146690   \n",
       "2       3.763025 -24.287819  18.558378  24.320732  ... -23.039650   6.284547   \n",
       "3      14.640491 -28.468567  23.722717  22.710403  ... -25.556366   4.002686   \n",
       "4      11.384158 -23.531187  22.702066  23.904671  ... -24.457840  10.056759   \n",
       "...          ...        ...        ...        ...  ...        ...        ...   \n",
       "24995   4.257339  -4.647678   4.680054   2.775642  ...  -5.378468   6.225250   \n",
       "24996  10.503281 -13.057060  13.101852  12.770050  ... -15.988598   6.903183   \n",
       "24997   2.976837  -6.946411   7.065413   7.312721  ...  -7.426193   9.140686   \n",
       "24998   9.002274 -17.094444  12.638168   7.161171  ... -16.743801   0.952118   \n",
       "24999   9.659119  -9.665316  13.272865  13.193047  ... -12.379272   6.038727   \n",
       "\n",
       "             292        293        294        295       296        297  \\\n",
       "0     -33.328987   9.722412 -26.716827 -10.303997  2.579872 -19.129990   \n",
       "1     -12.804749   3.808205  -6.146217  -2.835491 -0.495293  -4.693481   \n",
       "2     -23.298676  15.287937 -12.791531  -5.257778  2.578659 -12.364639   \n",
       "3     -23.584404   9.610126 -10.111442  -2.726578  3.336586 -10.713562   \n",
       "4     -29.204399   6.255138 -14.498840  -0.895094  6.454372 -19.625992   \n",
       "...          ...        ...        ...        ...       ...        ...   \n",
       "24995  -7.275024   3.712402  -4.262329  -1.908768  4.530167  -3.873884   \n",
       "24996 -15.212250   2.484120  -5.440849  -1.743176  2.057991  -6.311344   \n",
       "24997 -10.666756   4.078735  -6.753197   0.665543 -0.919044  -7.831268   \n",
       "24998 -15.382585   2.369106 -11.096809  -1.904205 -0.214203  -5.103699   \n",
       "24999 -16.316090   5.599518  -8.328697  -1.204252 -1.484009  -5.121796   \n",
       "\n",
       "             298       299  \n",
       "0      11.317310 -4.080734  \n",
       "1       4.241936 -0.824364  \n",
       "2       8.910461  4.143981  \n",
       "3      16.601911  3.251701  \n",
       "4       0.599186  1.965607  \n",
       "...          ...       ...  \n",
       "24995  -0.512589  0.154842  \n",
       "24996   6.623047 -2.365334  \n",
       "24997   3.209351 -2.725433  \n",
       "24998  12.709579 -2.317215  \n",
       "24999   6.469944 -3.725159  \n",
       "\n",
       "[25000 rows x 300 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as model_api\n",
    "\n",
    "word_vectors = model_api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "words.columns = words.columns.astype(str)\n",
    "\n",
    "def soft_get(w):\n",
    "    try:\n",
    "        return word_vectors[w]\n",
    "    except KeyError:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "def map_vectors(row):\n",
    "    try:\n",
    "        return np.sum(\n",
    "            row.loc[row.notna()].apply(soft_get)\n",
    "        )\n",
    "    except:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "emb = pd.DataFrame(words.apply(map_vectors, axis=1))\n",
    "emb.columns = ['C']\n",
    "emb = pd.DataFrame(np.array(emb.C.apply(pd.Series)))\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Normalizer().fit_transform(emb)\n",
    "y = train['sentiment']\n",
    "emb = emb.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8592"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('reg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "error_score\n",
      "estimator__memory\n",
      "estimator__steps\n",
      "estimator__verbose\n",
      "estimator__pca\n",
      "estimator__std\n",
      "estimator__clf\n",
      "estimator__pca__copy\n",
      "estimator__pca__iterated_power\n",
      "estimator__pca__n_components\n",
      "estimator__pca__random_state\n",
      "estimator__pca__svd_solver\n",
      "estimator__pca__tol\n",
      "estimator__pca__whiten\n",
      "estimator__std__copy\n",
      "estimator__std__with_mean\n",
      "estimator__std__with_std\n",
      "estimator__clf__cv\n",
      "estimator__clf__error_score\n",
      "estimator__clf__estimator__C\n",
      "estimator__clf__estimator__break_ties\n",
      "estimator__clf__estimator__cache_size\n",
      "estimator__clf__estimator__class_weight\n",
      "estimator__clf__estimator__coef0\n",
      "estimator__clf__estimator__decision_function_shape\n",
      "estimator__clf__estimator__degree\n",
      "estimator__clf__estimator__gamma\n",
      "estimator__clf__estimator__kernel\n",
      "estimator__clf__estimator__max_iter\n",
      "estimator__clf__estimator__probability\n",
      "estimator__clf__estimator__random_state\n",
      "estimator__clf__estimator__shrinking\n",
      "estimator__clf__estimator__tol\n",
      "estimator__clf__estimator__verbose\n",
      "estimator__clf__estimator\n",
      "estimator__clf__iid\n",
      "estimator__clf__n_jobs\n",
      "estimator__clf__param_grid\n",
      "estimator__clf__pre_dispatch\n",
      "estimator__clf__refit\n",
      "estimator__clf__return_train_score\n",
      "estimator__clf__scoring\n",
      "estimator__clf__verbose\n",
      "estimator\n",
      "iid\n",
      "n_jobs\n",
      "param_grid\n",
      "pre_dispatch\n",
      "refit\n",
      "return_train_score\n",
      "scoring\n",
      "verbose\n"
     ]
    }
   ],
   "source": [
    "for param in grid.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('reg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "    'pca__n_components': np.arange(50, 60, 5),\n",
    "    'reg__fit_intercept': [True, False],\n",
    "    'reg__C': [2, 5, 3]\n",
    "}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   21.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 55, 'reg__C': 3, 'reg__fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "model = grid.best_estimator_\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8414\n",
      "[[2099  382]\n",
      " [ 411 2108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      2481\n",
      "           1       0.85      0.84      0.84      2519\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.84      0.84      0.84      5000\n",
      "weighted avg       0.84      0.84      0.84      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
